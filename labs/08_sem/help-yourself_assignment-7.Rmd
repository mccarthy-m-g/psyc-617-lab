---
title: "Help yourself: Assignment 7"
author:
  - name: "Michael McCarthy"
    url: https://github.com/mccarthy-m-g
    affiliation: "PSYC 617 Lab"
    affiliation_url: https://github.com/mccarthy-m-g/psyc-617-lab
repository_url: https://github.com/mccarthy-m-g/psyc-617-lab
output:
  distill::distill_article:
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, comment = "#>", collapse = TRUE)
```

## Prerequisites

To access the datasets, help pages, and functions that we will use in this *help yourself*, load the following packages:

```{r prerequisites}
here::i_am("labs/05_multilevel-modelling/help-yourself_assignment-4.Rmd")

library(here)
library(tidyverse)
library(broom)
library(lavaan)
library(tidySEM)
```

As well as this Help Yourself's example data:

```{r example-data}
teaching <- readr::read_csv(
  here::here("data", "help-yourself_a7_p1.csv"),
  col_types = "nnnn"
)

academics <- readr::read_csv(
  here::here("data", "help-yourself_a7_p2.csv"),
  col_types = "nnnnnnnnnnnnn"
)
```

## Notes on software

The **lavaan** package is the main R package for latent variable analysis, but there are other packages too. It is a commercial quality package, and can also mimic the results of several commercial programs (e.g., Mplus) if you ever need to do that.

There are some companion packages to lavaan that make certain things even easier, or extend its capabilities. The main one is the **semTools** package, which has tools for SEM (duh). There is also the **tidySEM** package, which provides a tidy framework for working with lavaan models (and has some other helpers). Finally, there are currently two mature packages that are available to make SEM graphs: tidySEM and semPlot. We will use the tidySEM package here. Both packages use the **igraph** package as their backend for creating SEM graphs. The tidySEM package makes it a bit easier to customize graphs though.

There is also the **blavaan** package if you want to take a Bayesian approach to SEM.

The lavaan package has an excellent tutorial available here <https://lavaan.ugent.be/tutorial/index.html>. You should take the time to read it.

## lavaan syntax

The lavaan tutorial describes lavaan syntax in full here <https://lavaan.ugent.be/tutorial/syntax1.html> and here <https://lavaan.ugent.be/tutorial/syntax2.html>. Briefly, the current set of formula types is summarized in the table below.

| formula type               | operator | mnemonic           |
|----------------------------|----------|--------------------|
| latent variable definition | =~       | is measured by     |
| regression                 | ~        | is regressed on    |
| (residual) (co)variance    | ~~       | is correlated with |
| intercept                  | ~ 1      | intercept          |

When defining a SEM model you can choose to define every single part (i.e., have full control) or define the main parts of the model and let lavaan handle the rest behind the scenes. Again, see the lavaan tutorial site for details. Here we will let lavaan handle things behind the scenes because it is sufficient for what we are doing.

## Path analysis

Since SEM models tend to be big, we first define our model before fitting it. In lavaan, models are written as strings. I like to enclose the strings in parentheses, as it allows you to save the object no matter where your cursor is in the string. Aside from the formulas you write for your model, you can also include comments and line breaks within the string---take advantage of this to make your models more readable.

```{r}
teaching_model <- ("
  # Regressions
  good_teaching ~ months_teaching + knowledge 
  months_teaching ~ knowledge + sensitivity
  
  # Correlations
  knowledge ~~ sensitivity
")
```

If we are following a coding style guide (and we should be), we ideally do not want to exceed 80 characters in a line. But if there are a lot of terms for a given regression or latent variable it can be easy to exceed that. The solution is simply to split up the definition over multiple lines. Here we will split the `good_teaching` regression over multiple lines. This model is equivalent to the one above.

```{r}
teaching_model <- ("
  # Regressions
  good_teaching ~ months_teaching 
  good_teaching ~ knowledge 
  months_teaching ~ knowledge + sensitivity
  
  # Correlations
  knowledge ~~ sensitivity
")
```

Once you have defined your model you can use the `sem()` function (`?lavaan::sem`) from the lavaan package to fit the model.

```{r}
fit_teaching_model <- lavaan::sem(teaching_model, data = teaching)
```

Once the model has been fitted, you can use the `summary()` function (`?lavaan::`summary,lavaan-method``) to get a summary of the fitted model.

```{r}
summary(fit_teaching_model)
```

This looks bare bones. The `summary()` function has a number of optional arguments to show or hide different summary information. Here are all the options, and their default values: `header = TRUE, fit.measures = FALSE, estimates = TRUE, ci = FALSE, fmi = FALSE, standardized = FALSE, remove.step1 = TRUE, cov.std = TRUE, rsquare = FALSE, std.nox = FALSE, modindices = FALSE, ci = FALSE, nd = 3L`.

Note that when `standardized=TRUE` SEs and tests are still based on unstandardized estimates. Use the `standardizedSolution()` function (`?lavaan::standardizedSolution`) to obtain standardized SEs and test statistics for standardized estimates. This argument simply adds two extra columns of standardized parameter values to the summary: the `Std.lv` column contains estimates when only the latent variables are standardized, and the `Std.all` column contains estimates when both latent and observed variables are standardized.

```{r}
summary(
  fit_teaching_model,
  fit.measures = TRUE,
  rsquare = TRUE,
  standardized = TRUE
)
```

### Inspecting models

If you need to extract any of the values in the summary for further processing, lavaan provides a number of helper functions described here <https://lavaan.ugent.be/tutorial/inspect.html>. Some of these can also be useful for diagnostics.

The `parameterEstimates()` function (`?lavaan::parameterEstimates`) returns a data frame containing all the model parameters in the rows.

```{r}
lavaan::parameterEstimates(fit_teaching_model)
```

The `standardizedSolution()` function (`?lavaan::standardizedSolution`) returns a data frame containing the standardized model parameters.

```{r}
lavaan::standardizedSolution(fit_teaching_model)
```

You can also use the `tidy()` function (`?broom::tidy.lavaan`) from the broom package, which gives unstandardized and standardized model parameters.

```{r}
broom::tidy(fit_teaching_model, conf.int = TRUE)
```

The `fitted()` function returns the model-implied (fitted) covariance matrix (and mean vector) of a fitted model.

```{r}
fitted(fit_teaching_model)
```

The `lavResiduals()` function (`?lavaan::lavResiduals`) returns residuals and standardized residuals of a fitted model as well as various summaries of these residuals.

```{r}
lavaan::lavResiduals(fit_teaching_model)
```

The `vcov()` function returns the estimated covariance matrix of the parameter estimates.

```{r}
vcov(fit_teaching_model)
```

The `fitMeasures()` function (`?lavaan::fitMeasures`) returns either all or a selection of fit measures as a named numeric vector.

```{r}
# Return all
lavaan::fitMeasures(fit_teaching_model)

# Return a selection
lavaan::fitMeasures(
  fit_teaching_model,
  fit.measures = c("aic", "bic", "rmsea")
)
```

The `glance()` function (`?broom::glance.lavaan`) from the broom package can also be used to return a selection of common fit measures.

```{r}
broom::glance(fit_teaching_model)
```

The `lavInspect()` function (`?lavaan::lavInspect`) can be used to inspect/extract information that is stored inside (or can be computed from) a fitted lavaan object. There are a lot of things you can extract; see the help page for more details.

```{r}
lavaan::lavInspect(fit_teaching_model, what = "free")
```

## Latent variable analysis

Latent variable analysis (i.e., SEM) follows the same procedure as path analysis. The only difference is that we also include latent variable definitions in our model.

```{r}
academics_model <- ("
  # Latent variable definitions
  efficacy =~ succeed + intellect + writing
  commitment =~ reputation + programs + ranking
  encouragement =~ parents + role + relatives
  social =~ office + greek + clubs
  
  # Regressions
  commitment ~ efficacy + encouragement
  social ~ efficacy + encouragement + commitment
  gpa ~ commitment + social
  
  # Correlations
  efficacy ~~ encouragement
")

fit_academics_model <- lavaan::sem(academics_model, data = academics)

summary(
  fit_academics_model,
  fit.measures = TRUE,
  rsquare = TRUE,
  standardized = TRUE
)
```

## Model identification

There are three approaches to achieving identification with SEM. For a brief overview see "A Non-arbitrary Method of Identifying and Scaling Latent Variables in SEM and MACS Models" <https://www.tandfonline.com/doi/abs/10.1207/s15328007sem1301_3>.

- Marker-Variable Method: the intercept of one of the indicators of each construct is fixed to be 0 and the loading of the chosen indicator is fixed to be 1.
- Reference-Group Method: the latent variance of each latent variable in the first group or at the first occasion is fixed to 1 and the latent mean is fixed to 0.
- Effects-Coding Method: the set of indicator intercepts are constrained to sum to zero for each construct and the set of loadings for a given construct to average 1 (this is analogous to analysis of variance effects coding)

In the example above we used the marker-variable method, with the first indicator in each latent variable definition being the one we fixed. This is the default identification behaviour in lavaan.

If you want to use the reference-group method, the `sem()` function has an optional `std.lv` argument that will fit your model with  the reference-group method when set to `TRUE`. Note that if a latent variable in your model is a dependent variable then the residual variance will be fixed to 1, which will have an impact on various estimates. You can always manually specify how variables are fixed in your model if you need more control in situations such as this.

If you want to use the effects-coding method you will have to specify it manually in your model.

Note that if you are specifying the finer details of your model manually, and want to be certain everything is exactly as you intend, you may prefer to use the `lavaan()` function (`?lavaan::lavaan`) instead of the `sem()` function. The `sem()` function is simply a wrapper for the more general `lavaan()` function with a number of default options set up. The `lavaan()` function on the other hand has no default options, so you have to be explicit about every part of your model in order to fit it.

## Graphs

You can use the `graph_sem()` function (`?tidySEM::graph_sem`) from the tidySEM package to graph your lavaan models.

```{r}
tidySEM::graph_sem(model = fit_academics_model)
```

As you may have noticed, this graph is not very readable. You have a few options here:

1. Try a different layout algorithm using the `get_layout()` (`?tidySEM::get_layout`) function
2. Manually specify a layout using the `get_layout()` (`?tidySEM::get_layout`) function
3. Draw the graph yourself in a different program

For the assignment or during the draft stage of a project, go with the first option. It's the quickest. For final publication, either option two or three are valid if you need fine control, but I would not do either of these until you are 100% certain your project is complete, otherwise you may end up wasting your time. The second option is nice because it ensures your results are reproducible and without error (e.g., from typos), but it's kind of a pain. The third option is probably the easiest if there's a program you are comfortable creating diagrams with. Apple Pages or Keynote, or MS Word or Powerpoint can be perfectly fine for this.

Here's how to change layout algorithms. Available algorithms include: "layout_as_star", "layout_as_tree", "layout_in_circle", "layout_nicely", "layout_on_grid", "layout_randomly", "layout_with_dh", "layout_with_fr", "layout_with_gem", "layout_with_graphopt", "layout_with_kk", "layout_with_lgl", "layout_with_mds". You may want to set a seed with the `set.seed()` function first so you get a consistent result (some of the algorithms are random so you'll get something different each time otherwise).

```{r}
set.seed(664)
academics_model_layout <- tidySEM::get_layout(
  fit_academics_model,
  layout_algorithm = "layout_nicely"
)

# Unstandardized estimates
tidySEM::graph_sem(
  model = fit_academics_model,
  layout = academics_model_layout
)

# If you want standardized estimates you can edit the label used for the edges
# in the graph.
# See: https://cjvanlissa.github.io/tidySEM/articles/Plotting_graphs.html
fit_academics_model %>% 
  prepare_graph(layout = academics_model_layout) %>% 
  # Make sure to include the curly braces here, otherwise the expression will
  # be ignored. Here we change the label to use standardized estimates with
  # significance stars. You could also do `est_std` if you don't want stars.
  edit_edges({label = est_sig_std}) %>% 
  plot()
```

As far as saving the graph, probably the least painful way would be to click the zoom button in the viewer window, adjust the window until the graph looks the way you want, then right-click and save the image. Then you can display the image in the same way we display any other image in an R Markdown document. Otherwise you can play around with knitr's figure size chunk options.

For more details on graphs and customizing them, see the plotting graphs for structural equation models article for the tidySEM package <https://cjvanlissa.github.io/tidySEM/articles/Plotting_graphs.html>.

## Follow up tests

You can follow up lavaan models with the **emmeans** package as usual. The support for this is currently located in the semTools package, so you will need to load that first, but otherwise it should just work. The semTools package itself also has tools to follow up lavaan models; Alexander Schoemann and Terrence Jorgensen have an excellent tutorial on Testing and Interpreting Latent Variable Interactions Using the semTools Package <https://doi.org/10.3390/psych3030024>.

## Ordinal indicators

If your indicators are ordinal rather than continuous, it is probably a good idea to treat them as such. Coding ordinal data as if it is continuous is possible (e.g., you could rank people's heights from tallest to shortest, and then treat each person's rank as a continuous number); however, because we do not have information about the underlying continuous phenomenon, there is no guarantee that the coding rule used for each rank will correspond to the magnitude of change occurring in the underlying continuous phenomenon were we to analyze them as metric.

In the height example, if we chose ranks of 1, 2, 3, 4, and so on, and then treated those ranks as a continuous metric, it's likely our model would be biased. Here we would be assuming the difference in height from rank to rank is equal between all people in our sample. This is obviously nonsense. The difference in height from rank to rank is going to vary. So, if we did this, it would lead to biased estimates. And the size of the differences in numeric scores will largely be an artifact of our coding rule. If we chose a different coding rule we would obtain different results, biased in their own way.

Here it is important to note that common methods of measurement in psychology, such as *Likert scales*, are likely best treated as ordinal.

Fortunately lavaan makes it easy to work with ordinal data. The optional `ordered` argument can be used to tell lavaan which variables in your data should be treated as ordinal. If all your endogenous variables are ordinal you can also set it to `TRUE` and then all of them will be treated as such. This will use diagonally weighted least squares with polychoric correlations as your estimation method, rather than maximum likelihood, which tends to be more accurate when you have ordinal variables (which by their very nature will violate multivariate normality, and thus a key assumption of maximum likelihood estimation).

Here are a couple papers as a jumping off point. Some of the books in the learning more section also dicuss these issues.

- The performance of ML, DWLS, and ULS estimation with robust corrections in structural equation models with ordinal variables <https://pubmed.ncbi.nlm.nih.gov/27571021/>
- Factor Analysis with Ordinal Indicators: A Monte Carlo Study Comparing DWLS and ULS Estimation <https://www.tandfonline.com/doi/abs/10.1080/10705510903203573?journalCode=hsem20>

And here are two excellent papers about considerations when working with ordinal data more generally.

- Levels of measurement and statistical analyses <https://open.lnu.se/index.php/metapsychology/article/view/1916>
- Analyzing Ordinal Data with Metric Models: What Could Possibly Go Wrong? <https://papers.ssrn.com/abstract=2692323>

## SEM vs mixed models

Mixed models can be used in a SEM framework too. Here's a demonstration using the data from the mixed models lab.

```{r}
sales <- readr::read_csv(
  here::here("data", "help-yourself_a4.csv"),
  col_types = "fnfnfn"
)
```

Currently lavaan only supports two level models with random intercepts with continuous data. It should support more flexible models in the future. The main point here is just to show that mixed models can be thought of as a special case of SEM.

First with the lme4 package.

```{r}
sales_mixed_model_lme4 <- lme4::lmer(
  sales ~ years_experience + dealership_awards + (1 | dealership),
  data = sales
)

summary(sales_mixed_model_lme4)
```

Then with the lavaan package. There are some minor differences in the estimates, but they are the same by any practical measure.

```{r}
sales_mixed_model_lavaan <- ("
  Level: 1
      sales ~ years_experience
  Level: 2
      sales ~ dealership_awards
")

fit_sales_mixed_model_lavaan <- lavaan::sem(
  sales_mixed_model_lavaan,
  data = sales,
  cluster = "dealership"
)

summary(fit_sales_mixed_model_lavaan)
```

Michael Clark has a nice comparison of SEM and mixed models if you want to dive into this further, and get some thoughts on which approach to take <http://m-clark.github.io/docs/mixedModels/growth_vs_mixed_old.html>. Yves Rosseel, the creator of the lavaan package, also has some excellent lecture notes on multilevel SEM with lavaan <https://users.ugent.be/~yrosseel/lavaan/zurich2020/lavaan_multilevel_zurich2020.pdf>, and the lavaan website has a tutorial <https://lavaan.ugent.be/tutorial/multilevel.html> (note that the lavaan package does not yet support random slopes in multilevel SEM).

And here are some papers:

- Have multilevel models been structural equation models all along? <https://pubmed.ncbi.nlm.nih.gov/26777445/>
- Estimating Multilevel Linear Models as Structural Equation Models. <https://journals.sagepub.com/doi/10.3102/10769986028002135>
- People are variables too: Multilevel structural equations modeling. <https://pubmed.ncbi.nlm.nih.gov/16221028/>

This is quite cool, I think, as it ties nearly everything you have learned in PSYC 615 and 617 under a single modelling framework. The other reason it's cool is that it means you can do things like multilevel exploratory or confirmatory factor analysis, or multilevel SEM. Here's a paper that discusses this:

- Using Multilevel Factor Analysis With Clustered Data: Investigating the Factor Structure of the Positive Values Scale <https://journals.sagepub.com/doi/pdf/10.1177/0734282915570278>

## Full circle

Last thing in the course! Hopefully this drives home the point that you shouldn't take a cookbook approach to statistics. You may have been taught that way, but you do not need to think that way. We're going to use the very first data set you did a student's t-test on in PSYC 615 for this one, but we're now going to do the t-test as a path model. This answer about using SEM to run one-way and two-way ANOVAs on Cross Validated makes a good reference for the various ways to do this <https://stats.stackexchange.com/a/453558/337979>.

```{r}
spiders <- readr::read_csv(
  here::here("data", "help-yourself_psyc-615_a1.csv"),
  col_types = "ffn"
) 
```

Here's the student's t-test.

```{r}
t.test(anxiety ~ group, var.equal = TRUE, data = spiders)
```

Here's the student's t-test as a path model. There are two ways to go about this. First, we could simply do a regression with lavaan.

```{r}
spiders_model <- ("
  anxiety ~ group
")

fit_spiders_model <- lavaan::sem(
  spiders_model,
  data = spiders
)

summary(fit_spiders_model)
```

You could also make a graph of this, like any other path or SEM model. And since nearly everything you have learned from PSYC 615 and 617 is just some special case of SEM, you can create graphs of all those methods too. 

```{r}
tidySEM::graph_sem(model = fit_spiders_model)
```

The second way we could go about this is to fit two multigroup intercept-only path models, then compare the fit of the two models to the data using a likelihood ratio test. In this case, one model would allow the intercepts to be freely estimated between the two groups, and the other model would constrain the intercepts to be equal between the two groups. Since the intercepts are just the group means here, if they are similar then the constrained model should have a fit similar to the free model; if they are different then the free model should fit the data better than the constrained model.

Note that the values in the likelihood ratio test won't line up with the values from the t-test with this approach. However, both approaches are testing a similar question.

In this example the multigroup path model is perhaps a bit silly (since you could just do a t-test), but the useful thing about this approach is that you can apply it to more complex path and SEM models and select specific paths or parts of the model to freely estimate and constrain.

This approach is also used in measurement invariance testing, which involves testing whether psychometric scales measure the same latent construct across different groups of interest (see the learning more section for some links).

```{r}
spiders_model <- ("
  anxiety ~ 1
")

fit_spiders_model_free <- lavaan::sem(
  spiders_model,
  data = spiders,
  group = "group"
)

summary(fit_spiders_model_free)

fit_spiders_model_fixed <- lavaan::sem(
  spiders_model,
  data = spiders,
  group = "group",
  group.equal = "intercepts"
)

summary(fit_spiders_model_fixed)

lavaan::lavTestLRT(fit_spiders_model_free, fit_spiders_model_fixed)
```

## Wrapping up

```{r}
knitr::include_graphics(here::here("images", "sem-meme.jpg"))
```

## Learning more

### SEM

- Principles and Practice of Structural Equation Modeling (Kline) <https://www.guilford.com/books/Principles-and-Practice-of-Structural-Equation-Modeling/Rex-Kline/9781462523344>
- Structural equation models and the quantification of behavior <https://www.pnas.org/content/108/Supplement_3/15639>
- Structural equation modelling in perspective <https://onlinelibrary.wiley.com/doi/abs/10.1002/job.4030160304>
- Jason Newsom's SEM course notes <http://web.pdx.edu/~newsomj/semclass/>
- David Kenny's SEM notes <http://davidakenny.net/cm/causalm.htm>
- Jon Lefcheck's SEM book <https://jslefche.github.io/sem_book/index.html>

### Longitudinal SEM

- Longitudinal Structural Equation Modeling (Little) <https://www.guilford.com/books/Longitudinal-Structural-Equation-Modeling/Todd-Little/9781462510160>
- Longitudinal Structural Equation Modeling: A Comprehensive Introduction (Newsom) <https://www.routledge.com/Longitudinal-Structural-Equation-Modeling-A-Comprehensive-Introduction/Newsom/p/book/9781848726970>

Note: These books are good references even if you aren't doing longitudinal analysis

### Multigroup SEM

- Multigroup Analysis and Moderation with SEM (Newsom) <https://web.pdx.edu/~newsomj/semclass/ho_moderation.pdf>
- Introduction to multigroup analysis <https://jslefche.github.io/sem_book/multigroup-analysis.html>
- Means, Groups, and Constraints in SEM <https://psu-psychology.github.io/psy-597-SEM/10_invariance_groups/invariance_groups_constraints.html>
- lavaan: multiple groups tutorial <https://lavaan.ugent.be/tutorial/groups.html>

### Measurement Invariance

- A Primer to (Cross-Cultural) Multi-Group Invariance Testing Possibilities in R <https://www.frontiersin.org/article/10.3389/fpsyg.2019.01507/full>
- The measurement invariance chapter in the Longitudinal Structural Equation Modeling book by Newsom is also good

### Model identification

- Testing parameters in structural equation modeling: every "one" matters <https://pubmed.ncbi.nlm.nih.gov/11570231/>
- When constraints interact: a caution about reference variables, identification constraints, and scale dependencies in structural equation modeling <https://pubmed.ncbi.nlm.nih.gov/12090411/>

### Cross validation

-   Multiple Comparison and Cross-Validation in Evaluating Structural Equation Models <https://link.springer.com/chapter/10.1007/978-3-319-13248-8_83>
-   Alternative Strategies for Cross-Validation of Covariance Structure Models <https://pubmed.ncbi.nlm.nih.gov/26771552/>

### Correlation

- Introduction to the Tetrachoric and Polychoric Correlation Coefficients <http://www.john-uebersax.com/stat/tetra.htm>

### GLM comparison

- The paired t-test as a simple latent change score model <https://doi.org/10.3389/fpsyg.2013.00738>

### Thinking critically

- Thinking Twice About Sum Scores <https://psyarxiv.com/3wy47/>
- Measuring the Mind: Conceptual Issues in Contemporary Psychometrics <https://doi.org/10.1017/CBO9780511490026>
- Multiplicity Control in Structural Equation Modeling <https://www.tandfonline.com/doi/abs/10.1080/10705510709336738?journalCode=hsem20>
- The Myth of Global Fit Indices and Alternatives for Assessing Latent Variable Relations <https://doi.org/10.1177%2F1094428110391472>

### Cross Validated

- Whether to use structural equation modelling to analyse observational studies in psychology <https://stats.stackexchange.com/a/187406/337979>
- Using SEM to run one-way and two-way ANOVAs <https://stats.stackexchange.com/a/453558/337979>

### R Packages

-   [semTools](https://github.com/simsem/semTools/tree/master/semTools)
-   [tidySEM](https://cjvanlissa.github.io/tidySEM/)
